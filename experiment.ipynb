{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with recognizing times from MK8DX screenshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import io\n",
    "import datetime as dt\n",
    "import subprocess\n",
    "from mindee import Client, AsyncPredictResponse, product\n",
    "from dotenv import load_dotenv, dotenv_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init a new client\n",
    "mindee_client = Client(api_key=os.getenv('MINDEE_API_KEY'))\n",
    "\n",
    "endpoint_kind_1 = mindee_client.create_endpoint(\n",
    "    account_name=\"polimath\",\n",
    "    endpoint_name=\"mk8dx_screen_capture_kind_1\",\n",
    "    version=\"1\"\n",
    ")\n",
    "endpoint_kind_2 = mindee_client.create_endpoint(\n",
    "    account_name=\"polimath\",\n",
    "    endpoint_name=\"mk8dx_screen_capture_kind_2\",\n",
    "    version=\"1\"\n",
    ")\n",
    "#endpoint_kind_3 = mindee_client.create_endpoint(\n",
    "#    account_name=\"polimath\",\n",
    "#    endpoint_name=\"mk8dx_screen_capture_kind_3\",\n",
    "#    version=\"1\"\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify which kind of image we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a way to distinguish among at least three image formats:\n",
    "1. Blue background, track name at bottom, combo listed with text.\n",
    "2. Track background, racing alone (no ghost).\n",
    "3. Track background, racing against ghost.\n",
    "\n",
    "We also need a way to identify how many laps there are in the race. This can be either three or seven, with three being the most common."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine kind of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageToOCR():\n",
    "    def __init__(self, image_file_name):\n",
    "        self.image_file_name = image_file_name\n",
    "    \n",
    "    @property\n",
    "    def ocr(self) -> str:\n",
    "        ocr_result = subprocess.run(['ocrs', self.image_file_name], stdout=subprocess.PIPE)\n",
    "        return ocr_result.stdout.decode('utf-8').strip()\n",
    "    \n",
    "    def ocr_box(self, box: list[4]) -> str:\n",
    "        \"\"\"\n",
    "        Given a box defining opposite corners of a box in pixels,\n",
    "        return the text ocr'ed from that box.\n",
    "\n",
    "        box = a list of integers: [x1, y1, x2, y2]\n",
    "        \"\"\"\n",
    "        original_image = Image.open(self.image_file_name)\n",
    "        cropped_image = original_image.crop(box)\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as temporary_file:\n",
    "            temporary_file_name = temporary_file.name\n",
    "        cropped_image.save(temporary_file_name)\n",
    "        ocr_result = subprocess.run(['ocrs', temporary_file_name], stdout=subprocess.PIPE)\n",
    "        \n",
    "        return ocr_result.stdout.decode('utf-8').strip()\n",
    "    \n",
    "    def ocr_mindee(self, kind: int) -> dict:\n",
    "        input_doc = mindee_client.source_from_path(self.image_file_name)\n",
    "        if kind in [1,2,3]:\n",
    "            result: AsyncPredictResponse = mindee_client.enqueue_and_parse(\n",
    "                product.GeneratedV1,\n",
    "                input_doc,\n",
    "                endpoint=eval('endpoint_kind_' + str(kind))\n",
    "            )\n",
    "            return {k:v.value for k,v in result.document.inference.prediction.fields.items()}\n",
    "        else:\n",
    "            return {}\n",
    "    \n",
    "    @property\n",
    "    def kind(self) -> int:\n",
    "        with Image.open(self.image_file_name) as f:\n",
    "            image_size = f.size\n",
    "        \n",
    "        lower_right_OK = self.ocr_box(box=[1170, 646, 1225, 682])\n",
    "        lower_right_lap_2_number = self.ocr_box(box=[1020, 456, 1044, 480])\n",
    "        last_digit_top_lap_2 = self.ocr_box(box=[1162, 220, 1183, 253])\n",
    "\n",
    "        if image_size != (1280, 720):\n",
    "            # Wrong size; can't be a screen capture from the Switch\n",
    "            image_kind = 0\n",
    "        elif lower_right_OK == 'OK':\n",
    "            # Looks for 'OK' in the lower left corner\n",
    "            image_kind = 1\n",
    "        elif lower_right_lap_2_number == '2':\n",
    "            # Looks for the second lap in the lower box of times.\n",
    "            # Assumes that the course has three laps.\n",
    "            image_kind = 3\n",
    "        elif len(last_digit_top_lap_2) is not None:\n",
    "            # If there's no lower box of times, looks for the second lap\n",
    "            # in the upper box of times.\n",
    "            image_kind = 2\n",
    "        else:\n",
    "            # Can't positively identify as one of the defined kinds.\n",
    "            image_kind = 0\n",
    "        return image_kind\n",
    "    \n",
    "    def pull_data_from_image(self, kind=None) -> dict:\n",
    "        \"\"\"\n",
    "        Pulls information from image. Returns a dictionary of strings.\n",
    "        \"\"\"\n",
    "        if kind == None:\n",
    "            return self.pull_data_from_image(kind=self.kind)\n",
    "        if kind not in [1,2,3]:\n",
    "            return {}\n",
    "        else:\n",
    "            mindee_extract = self.ocr_mindee(kind=kind)\n",
    "            return mindee_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/test_images/2019102710534900_c.jpg: 1\n",
      "{'glider': 'Gold Glider', 'lap_1_time': '0:28.703', 'lap_2_time': '0:28.330', 'lap_3_time': '0:27.706', 'overall_time': '1:24.799', 'racer': 'Ander', 'track': 'GCN Yoshi Circuit', 'vehicle': 'Biddybuggy', 'wheels': 'Roller'}\n"
     ]
    }
   ],
   "source": [
    "# kind 1\n",
    "image_file = 'data/test_images/2019102710534900_c.jpg'\n",
    "print(image_file + ': ' + str(ImageToOCR(image_file).kind))\n",
    "print(ImageToOCR(image_file).pull_data_from_image(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/test_images/2023062418352400_s.jpg: 2\n",
      "{'character_name': 'Dry Bones', 'glider': 'Cloud Glider', 'lap_1_time': '0:37.501', 'lap_2_time': '0:33.703', 'lap_3_time': '0:34.005', 'overall_time': '8:45.209', 'vehicle': 'Biddybuggy', 'wheels': 'Azure Roller'}\n"
     ]
    }
   ],
   "source": [
    "# kind 2\n",
    "image_file = 'data/test_images/2023062418352400_s.jpg'\n",
    "print(image_file + ': ' + str(ImageToOCR(image_file).kind))\n",
    "print(ImageToOCR(image_file).pull_data_from_image(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kind 3\n",
    "image_file = 'data/test_images/2023070714422000_s.jpg'\n",
    "print(image_file + ': ' + str(ImageToOCR(image_file).kind))\n",
    "print(ImageToOCR(image_file).pull_data_from_image(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/test_images/dog.jpg: 0\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# kind other\n",
    "image_file = 'data/test_images/dog.jpg'\n",
    "print(image_file + ': ' + str(ImageToOCR(image_file).kind))\n",
    "print(ImageToOCR(image_file).pull_data_from_image(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still some problems with accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE IN CASE WE NEED THE COORDINATES\n",
    "if kind == None:\n",
    "            return self.pull_data_from_image(kind=self.kind)\n",
    "        if kind not in [1,2,3]:\n",
    "            return {}\n",
    "        if kind == 1:\n",
    "            racer = self.ocr_box(box=[788, 110, 1074, 143])\n",
    "            overall_time = self.ocr_box(box=[870, 144, 1075, 190])\n",
    "            lap_times = {\n",
    "                1: self.ocr_box(box=[866, 210, 1026, 250]),\n",
    "                2: self.ocr_box(box=[866, 250, 1026, 290]),\n",
    "                3: self.ocr_box(box=[866, 290, 1026, 330])\n",
    "            }\n",
    "            vehicle = self.ocr_box(box=[830, 350, 1100, 390])\n",
    "            wheels = self.ocr_box(box=[830, 410, 1100, 450])\n",
    "            glider = self.ocr_box(box=[830, 470, 1100, 510])\n",
    "            track = self.ocr_box(box=[300, 640, 830, 690])\n",
    "            output = {\n",
    "                'racer': racer,\n",
    "                'overall_time': overall_time,\n",
    "                'lap_times': lap_times,\n",
    "                'vehicle': vehicle,\n",
    "                'wheels': wheels,\n",
    "                'glider': glider,\n",
    "                'track': track\n",
    "            }\n",
    "        elif kind == 2:\n",
    "            character_name = self.ocr_box(box=[615, 120, 920, 155])\n",
    "            overall_time = self.ocr_box(box=[1039, 113, 1210, 152])\n",
    "            lap_times = {\n",
    "                1: self.ocr_box(box=[1047, 145, 1200, 210]),\n",
    "                2: self.ocr_box(box=[1047, 222, 1200, 253]),\n",
    "                3: self.ocr_box(box=[1047, 264, 1200, 298])\n",
    "            }\n",
    "            vehicle = self.ocr_box(box=[671, 171, 973, 202])\n",
    "            wheels = self.ocr_box(box=[671, 220, 973, 252])\n",
    "            glider = self.ocr_box(box=[671, 265, 973, 298])\n",
    "            output = {\n",
    "                'character_name': character_name,\n",
    "                'overall_time': overall_time,\n",
    "                'lap_times': lap_times,\n",
    "                'vehicle': vehicle,\n",
    "                'wheels': wheels,\n",
    "                'glider': glider\n",
    "            }\n",
    "        elif kind == 3:\n",
    "            output = {}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
